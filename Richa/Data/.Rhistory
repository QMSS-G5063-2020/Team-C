facet_wrap(~ Country) +
coord_flip()+ theme_clean()+
#theme(panel.background = element_rect(fill = "white",
#colour = "black",
#size = 0.5,
#linetype = "solid"),
#panel.grid.major.y = element_blank(),
#panel.grid.major.x = element_line(size = .1,
# color = "black",
#linetype = "dashed"))
scale_fill_manual(values = usecol(pal_unikn_pair, n = 3, alpha = 0.8)) +
labs(x = "Common Words",
y = "Frequency",
title = "Frequent Common Words by Country")
library(ggplot2)
library(dplyr)
library(stringi)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(corpus)
library(purrr)
library(gower)
library(lme4)
library(multcomp)
library(mvtnorm)
library(corpustools)
text1 <- readLines("Data/syria_v1.txt")
cloud1 <- Corpus(VectorSource(text1))
removeNumPunct <- function(x) {
gsub("[^[:alpha:][:space:]]*", "", x)
}
removeAllCaps <- function(x) {
gsub("\b[A-Z]+\b", "", x)
}
clean_corpus <- function(corpus) {
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(removeAllCaps))
corpus <- tm_map(corpus, content_transformer(tolower))
#adding too common and not insightful words to the stopwords list
corpus <- tm_map(corpus, removeWords, c("syria","syrian","south","sudan","venezuela","venezuelas","venezuelans","venezuelan","year","years","one","two","three","later","since","month","months","didnt","first","second","third","back","even","now","among","may","get","day","yet","say","country","countries","countrys","president","middle","many","still","says", "bus","left","like","want", "sudanese","sudans","refugee", stopwords("en")))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
suc_clean1 <- clean_corpus(cloud1)
suc_tdm1 <- TermDocumentMatrix(suc_clean1)
suc_m1 <- as.matrix(suc_tdm1)
suc_v1 <- sort(rowSums(suc_m1), decreasing = TRUE)
suc_d1 <- data.frame(word = names(suc_v1), freq = suc_v1)
set.seed(1234)
wordcloud(
words = suc_d1$word,
freq = suc_d1$freq,scale = c(2, 0.4),
min.freq = 5,
max.words = 100,
random.order = FALSE,
rot.per = 0.3,
colors = brewer.pal(8, "Dark2")
)
library(wbstats)
library(ggplot2)
library(tidyverse)
library(lubridate)
library(ggthemes)
library(viridis)
gdp_data_syr <- wbstats::wb(country = "SYR",
indicator = c("NY.GDP.PCAP.KD.ZG") , startdate = 2000, enddate = 2017)
gdp_data_syr$date <- as.numeric(gdp_data_syr$date)
gdp_data_syr %>%
ggplot(aes(x = factor(date), y = value, group = 1)) +
geom_line(group = 1) + ylab("GDP per capita growth") +xlab(NULL) +
geom_hline(yintercept = 0, color = "red") +
labs(title = "GDP Growth Rate",
subtitle = "Movement of GDP per capita growth rate from 2000-2007",
caption = "source: World Bank, Global Poverty Working Group.", parse = TRUE) +
theme_minimal()
# Importing migrant origin and destination numbers for Syria
destination_data <- readxl::read_excel("Data/UN_MigrantStockByOriginAndDestination_2019.xlsx", sheet = 2, skip = 15, col_names = TRUE, trim_ws = TRUE)
# Subsetting origin to Syria
destination_data_syr <- destination_data %>%
dplyr::filter(...3 == "Syrian Arab Republic")
destination_data_syr$Total <- destination_data_syr$Total %>%
as.numeric()
# Subsetting origin to Syria and also 2018. This will be used in the map.
destination_data_syr_2019 <- destination_data_syr %>%
dplyr::filter(...1 == 2019)
# I am not interested in the first 9 columns. Only keeping columns which have data about the destination countries
destination_data_syr_2019 <- destination_data_syr_2019[c(10:241)]
# Making the table vertical- gather
destination_data_syr_2019 <- tidyr::gather(destination_data_syr_2019, key = "country", value = "value")
destination_data_syr_2019$value <- destination_data_syr_2019$value %>%
as.numeric()
destination_data_syr %>%
ggplot() +
geom_point(aes(x = factor(...1), y = Total)) +
geom_line(aes(x = factor(...1), y = Total, group = 1)) +
ylab(NULL) + xlab(NULL) +
geom_segment(aes(x = 3, xend = 3, y = 0, yend = 834916), color = "blue", size = 0.2) +
geom_label(aes(x = 3, y = 200000, label = "2000:\n Bashar Assad\ncomes to power"), size = 2.5) +
geom_segment(aes(x = 3.8, xend = 3.8, y = 0, yend = 851000), color = "blue", size = 0.2) +
geom_label(aes(x = 3.8, y = 500000, label = "2004:\n US imposes\nsanctions"), size = 2.5) +
geom_segment(aes(x = 5.2, xend = 5.2, y = 0, yend = 1600000), color = "blue", size = 0.2) +
geom_label(aes(x = 5.2, y = 1000000, label = "2011:\n Arab Spring\nSyrian Civil War begins"), size = 2.5) +
geom_segment(aes(x = 5.5, xend = 5.5, y = 0, yend = 1300000), color = "blue", size = 0.2) +
geom_label(aes(x=5.5, y=500000, label="2012:\nUN declares state of\ncivil war in Syria"),size=2.5) +
geom_segment(aes(x = 6.8, xend = 6.8, y = 0, yend = 867848), color = "blue", size = 0.2) +
geom_label(aes(x=6.8, y=200000, label="2018:\nUS-led missile\nstrikes"),size=2.5)
# importing the country centroid data
world <- rgdal::readOGR("Data/country_centroids_az8/country_centroids_az8.shp", verbose = FALSE)
# Merging data with shape file
world_syr <- merge(world, destination_data_syr_2019, by.x = "sovereignt", by.y = "country", all.x = TRUE)
world_syr_syr <- world_syr@data %>%
dplyr::filter(sovereignt == "Syria")
group <- c()
lng <- c()
lat <- c()
groupval = 1
for(i in 1:nrow(world_syr)){
# If there is a connection between destination and origin country
if(!is.na(world_syr$value[i])){
# Enter origin country first
group <- c(group, groupval)
lat <- c(lat, world_syr_syr$Latitude)
lng <- c(lng, world_syr_syr$Longitude)
# Enter destination country for same groupvalue
group <- c(group, groupval)
lat <- c(lat, world_syr$Latitude[i])
lng <- c(lng, world_syr$Longitude[i])
# Increment group val
groupval = groupval + 1
}
}
df_syr <- data.frame(group=group, lng=lng, lat=lat)
pal <- colorNumeric("Blues", df_syr$group)
content <- sprintf("<strong>%s</strong><br/>%g",
world_syr$sovereignt,
world_syr$value) %>% lapply(htmltools::HTML)
leaflet::leaflet() %>%
setView(lng = 38.50788, lat = 35.02547, zoom = 2) %>%
addTiles(options = providerTileOptions(minZoom = 2, maxZoom = 5)) %>%
addCircles(data = world_syr,
lat = world_syr$Latitude,
lng = world_syr$Longitude,
radius = world_syr$value,
fillColor = world_syr$value,
opacity = 0.8, fillOpacity = 0.7,
popup = content, label = content, labelOptions(
style = list("font-weight" = "normal", padding = "3px 8px"),
textsize = "15px",
direction = "auto")) %>%
addPolylines(data = df_syr,
lng = df_syr$lng,
lat = df_syr$lat,
group = df_syr$group,
color = pal(df_syr$group),
opacity = 0.1,
weight = 1,
fillOpacity = df_syr$group,
fillColor = pal(df_syr$group))
# Loading casuality data
cas_syr <- read.csv("Data/VDC_Syria_CASREP.csv", stringsAsFactors = FALSE)
# converting date into year
cas_syr$deathdate <- cas_syr$deathdate %>%
lubridate::as_date() %>%
lubridate::year()
# Aggregating the data, Selecting only civilians
cas_syr <- cas_syr %>%
filter(status == "Civilian") %>%
group_by(deathdate) %>%
summarise(count = n())
cas_syr %>%
arrange(deathdate) %>%
ggplot(aes(x=factor(deathdate), y=count, size=count, fill=factor(count))) +
geom_point(alpha=0.5, shape=21, color="black") +
scale_fill_viridis(discrete=TRUE, guide=FALSE, option="A") +
theme(legend.position="bottom") +
ylab("Deaths") +
xlab(NULL)+
theme(legend.position = "none") +
labs(title = "Civilian deaths due to the war (2011-2019)",
caption = "source: Casualty Reports from the Violations Documentation Center in Syria.", parse = TRUE)
library(ggplot2)
library(dplyr)
library(stringi)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(corpus)
library(purrr)
library(gower)
library(lme4)
library(multcomp)
library(mvtnorm)
library(corpustools)
# importing the country centroid data
world <- rgdal::readOGR("Data/country_centroids_az8/country_centroids_az8.shp")
# Merging data with shape file
world_syr <- merge(world, destination_data_syr_2019, by.x = "sovereignt", by.y = "country", all.x = TRUE)
world_syr_syr <- world_syr@data %>%
dplyr::filter(sovereignt == "Syria")
group <- c()
lng <- c()
lat <- c()
groupval = 1
for(i in 1:nrow(world_syr)){
# If there is a connection between destination and origin country
if(!is.na(world_syr$value[i])){
# Enter origin country first
group <- c(group, groupval)
lat <- c(lat, world_syr_syr$Latitude)
lng <- c(lng, world_syr_syr$Longitude)
# Enter destination country for same groupvalue
group <- c(group, groupval)
lat <- c(lat, world_syr$Latitude[i])
lng <- c(lng, world_syr$Longitude[i])
# Increment group val
groupval = groupval + 1
}
}
df_syr <- data.frame(group=group, lng=lng, lat=lat)
pal <- colorNumeric("Blues", df_syr$group)
content <- sprintf("<strong>%s</strong><br/>%g",
world_syr$sovereignt,
world_syr$value) %>% lapply(htmltools::HTML)
leaflet::leaflet() %>%
setView(lng = 38.50788, lat = 35.02547, zoom = 2) %>%
addTiles(options = providerTileOptions(minZoom = 2, maxZoom = 5)) %>%
addCircles(data = world_syr,
lat = world_syr$Latitude,
lng = world_syr$Longitude,
radius = world_syr$value,
fillColor = world_syr$value,
opacity = 0.8, fillOpacity = 0.7,
popup = content, label = content, labelOptions(
style = list("font-weight" = "normal", padding = "3px 8px"),
textsize = "15px",
direction = "auto")) %>%
addPolylines(data = df_syr,
lng = df_syr$lng,
lat = df_syr$lat,
group = df_syr$group,
color = pal(df_syr$group),
opacity = 0.1,
weight = 1,
fillOpacity = df_syr$group,
fillColor = pal(df_syr$group))
# Loading casuality data
cas_syr <- read.csv("Data/VDC_Syria_CASREP.csv", stringsAsFactors = FALSE)
# converting date into year
cas_syr$deathdate <- cas_syr$deathdate %>%
lubridate::as_date() %>%
lubridate::year()
# Aggregating the data, Selecting only civilians
cas_syr <- cas_syr %>%
filter(status == "Civilian") %>%
group_by(deathdate) %>%
summarise(count = n())
cas_syr %>%
arrange(deathdate) %>%
ggplot(aes(x=factor(deathdate), y=count, size=count, fill=factor(count))) +
geom_point(alpha=0.5, shape=21, color="black") +
scale_fill_viridis(discrete=TRUE, guide=FALSE, option="A") +
theme(legend.position="bottom") +
ylab("Deaths") +
xlab(NULL)+
theme(legend.position = "none") +
labs(title = "Civilian deaths due to the war (2011-2019)",
caption = "source: Casualty Reports from the Violations Documentation Center in Syria.", parse = TRUE)
getwd()
text2 <- readLines("Data/venezuela_v1.txt")
cloud2 <- Corpus(VectorSource(text2))
removeNumPunct <- function(x) {
gsub("[^[:alpha:][:space:]]*", "", x)
}
removeAllCaps <- function(x) {
gsub("\b[A-Z]+\b", "", x)
}
clean_corpus <- function(corpus) {
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(removeAllCaps))
corpus <- tm_map(corpus, content_transformer(tolower))
#adding too common and not insightful words to the stopwords list
corpus <- tm_map(corpus, removeWords, c("syria","syrian","south","sudan","venezuela","venezuelas","venezuelans","venezuelan","year","years","one","two","three","later","since","month","months","didnt","first","second","third","back","even","now","among","may","get","day","yet","say","country","countries","countrys","president","middle","many","still","says", "bus","left","like","want", "sudanese","sudans","refugee", stopwords("en")))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
suc_clean2 <- clean_corpus(cloud2)
suc_tdm2 <- TermDocumentMatrix(suc_clean2)
suc_m2 <- as.matrix(suc_tdm2)
suc_v2 <- sort(rowSums(suc_m2), decreasing = TRUE)
suc_d2 <- data.frame(word = names(suc_v2), freq = suc_v2)
set.seed(1234)
wordcloud(
words = suc_d2$word,
freq = suc_d2$freq,scale = c(2, 0.4),
min.freq = 5,
max.words = 100,
random.order = FALSE,
rot.per = 0.3,
colors = brewer.pal(8, "Dark2")
)
world <- rgdal::readOGR("Data/country_centroids_az8/country_centroids_az8.shp")
world_ven <- merge(world, destination_data_ven_2019, by.x = "sovereignt", by.y = "country", all.x = TRUE)
world <- rgdal::readOGR("Data/country_centroids_az8/country_centroids_az8.shp", verbose = FALSE)
world_ven <- merge(world, destination_data_ven_2019, by.x = "sovereignt", by.y = "country", all.x = TRUE)
library(wbstats)
library(ggplot2)
library(tidyverse)
library(leaflet)
gdp_data_ven <- wb(country = "VEN",
indicator = c("NY.GDP.PCAP.KD.ZG") , startdate = 2000, enddate = 2017)
gdp_data_ven$date <- as.numeric(gdp_data_ven$date)
gdp_data_ven %>%
ggplot(aes(x = factor(date), y = value, group = 1)) +
geom_line(group = 1) + ylab("GDP per capita growth") +xlab(NULL) + ylab(NULL) +
geom_hline(yintercept = 0, color = "red") +
labs(
title = "GDP per capita growth",
subtitle = "2000 - 2014",
caption = "source: World Bank, Global Poverty Working Group."
)
# Importing migrant origin and destination numbers for venezuela
destination_data <- readxl::read_excel("Data/UN_MigrantStockByOriginAndDestination_2019.xlsx", sheet = 2, skip = 15, col_names = TRUE, trim_ws = TRUE)
# Subsetting origin to Venezuela
destination_data_ven <- destination_data %>%
dplyr::filter(...3 == "Venezuela (Bolivarian Republic of)")
destination_data_ven$Total <- destination_data_ven$Total %>%
as.numeric()
# Subsetting origin to Venezuela and also 2018. This will be used in the map.
destination_data_ven_2019 <- destination_data_ven %>%
dplyr::filter(...1 == 2019)
# I am not interested in the first 9 columns. Only keeping columns which have data about the destination countries
destination_data_ven_2019 <- destination_data_ven_2019[c(10:241)]
# Making the table vertical- gather
destination_data_ven_2019 <- tidyr::gather(destination_data_ven_2019, key = "country", value = "value")
destination_data_ven_2019$value <- destination_data_ven_2019$value %>%
as.numeric()
options(scipen = 999)
destination_data_ven %>%
ggplot() +
geom_point(aes(x = factor(...1), y = Total)) +
geom_line(aes(x = factor(...1), y = Total, group = 1)) +
ylab(NULL) + xlab(NULL) +
geom_segment(aes(x = 1.1, xend = 1.1, y = 0, yend = 1000000), color = "blue", size = 0.2) +
geom_label(aes(x = 1.1, y = 800000, label = "1992:\n Venezuela is\n3rd richest country"), size = 2.5) +
geom_segment(aes(x = 2.9, xend = 2.9, y = 0, yend = 1000000), color = "blue", size = 0.2) +
geom_label(aes(x = 2.9, y = 800000, label = "1999:\n Chavez begins\nfirst term"), size = 2.5) +
geom_segment(aes(x = 3.3, xend = 3.3, y = 0, yend = 1010000), color = "blue", size = 0.2) +
geom_label(aes(x = 3.3, y = 500000, label = "2002:\n Armed forces\nrebel"), size = 2.5) +
geom_segment(aes(x = 5.5, xend = 5.5, y = 0, yend = 1385000), color = "blue", size = 0.2) +
geom_label(aes(x=5.5, y=500000, label="2013:\nPresident Chavez dies.\nMaduro elected"),size=2.5) +
geom_segment(aes(x = 5.8, xend = 5.8, y = 0, yend = 1400000), color = "blue", size = 0.2) +
geom_label(aes(x=6, y=1100000, label="2014:\nCentral Bank\n confirms recession"),size=2.5) +
labs(
title = "Evolution of migration",
subtitle = "1990 - 2019",
caption = "source: World Bank, Global Poverty Working Group."
)
world <- rgdal::readOGR("Data/country_centroids_az8/country_centroids_az8.shp", verbose = FALSE)
world_ven <- merge(world, destination_data_ven_2019, by.x = "sovereignt", by.y = "country", all.x = TRUE)
world_ven_ven <- world_ven@data %>%
dplyr::filter(sovereignt == "Venezuela")
content <- sprintf("<strong>%s</strong><br/>%g",
world_ven$sovereignt,
world_ven$value) %>% lapply(htmltools::HTML)
group <- c()
lng <- c()
lat <- c()
groupval = 1
for(i in 1:nrow(world_ven)){
# If there is a connection between destination and origin country
if(!is.na(world_ven$value[i])){
# Enter origin country first
group <- c(group, groupval)
lat <- c(lat, world_ven_ven$Latitude)
lng <- c(lng, world_ven_ven$Longitude)
# Enter destination country for same groupvalue
group <- c(group, groupval)
lat <- c(lat, world_ven$Latitude[i])
lng <- c(lng, world_ven$Longitude[i])
# Increment group val
groupval = groupval + 1
}
}
df_ven <- data.frame(group=group, lng=lng, lat=lat)
pal <- colorNumeric("Blues", df_ven$group)
leaflet::leaflet() %>%
setView(-66.1818412311, 7.12422421273, zoom = 2) %>%
#addProviderTiles(providers$MapBox, options = providerTileOptions(minZoom = 2, maxZoom = 5)) %>%
addTiles(options = providerTileOptions(minZoom = 2, maxZoom = 5)) %>%
addCircles(data = world_ven,
lat = world_ven$Latitude,
lng = world_ven$Longitude,
radius = world_ven$value,
fillColor = world_ven$value,
opacity = 0.8, fillOpacity = 0.7,
popup = content, label = content, labelOptions(
style = list("font-weight" = "normal", padding = "3px 8px"),
textsize = "15px",
direction = "auto")) %>%
addPolylines(data = df_ven,
lng = df_ven$lng,
lat = df_ven$lat,
group = df_ven$group,
color = pal(df_ven$group),
opacity = 0.1,
weight = 1,
fillOpacity = 0.25,
fillColor = pal(df_ven$group))
library(dplyr)
library(stringi)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(corpus)
library(purrr)
library(gower)
library(lme4)
library(multcomp)
library(mvtnorm)
library(corpustools)
text2 <- readLines("Data/venezuela_v1.txt")
cloud2 <- Corpus(VectorSource(text2))
removeNumPunct <- function(x) {
gsub("[^[:alpha:][:space:]]*", "", x)
}
removeAllCaps <- function(x) {
gsub("\b[A-Z]+\b", "", x)
}
clean_corpus <- function(corpus) {
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(removeAllCaps))
corpus <- tm_map(corpus, content_transformer(tolower))
#adding too common and not insightful words to the stopwords list
corpus <- tm_map(corpus, removeWords, c("syria","syrian","south","sudan","venezuela","venezuelas","venezuelans","venezuelan","year","years","one","two","three","later","since","month","months","didnt","first","second","third","back","even","now","among","may","get","day","yet","say","country","countries","countrys","president","middle","many","still","says", "bus","left","like","want", "sudanese","sudans","refugee", stopwords("en")))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
suc_clean2 <- clean_corpus(cloud2)
suc_tdm2 <- TermDocumentMatrix(suc_clean2)
suc_m2 <- as.matrix(suc_tdm2)
suc_v2 <- sort(rowSums(suc_m2), decreasing = TRUE)
suc_d2 <- data.frame(word = names(suc_v2), freq = suc_v2)
set.seed(1234)
wordcloud(
words = suc_d2$word,
freq = suc_d2$freq,scale = c(2, 0.4),
min.freq = 5,
max.words = 100,
random.order = FALSE,
rot.per = 0.3,
colors = brewer.pal(8, "Dark2")
)
library(ggplot2)
library(dplyr)
library(stringi)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(corpus)
library(purrr)
library(gower)
library(lme4)
library(multcomp)
library(mvtnorm)
library(corpustools)
text1 <- readLines("Data/ssudan_v1.txt")
cloud1 <- Corpus(VectorSource(text1))
text3 <- readLines("Data/ssudan_v1.txt")
cloud3 <- Corpus(VectorSource(text3))
removeNumPunct <- function(x) {
gsub("[^[:alpha:][:space:]]*", "", x)
}
removeAllCaps <- function(x) {
gsub("\b[A-Z]+\b", "", x)
}
clean_corpus <- function(corpus) {
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(removeAllCaps))
corpus <- tm_map(corpus, content_transformer(tolower))
#adding too common and not insightful words to the stopwords list
corpus <- tm_map(corpus, removeWords, c("syria","syrian","south","sudan","venezuela","venezuelas","venezuelans","venezuelan","year","years","one","two","three","later","since","month","months","didnt","first","second","third","back","even","now","among","may","get","day","yet","say","country","countries","countrys","president","middle","many","still","says", "bus","left","like","want", "sudanese","sudans","refugee", stopwords("en")))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
suc_clean3 <- clean_corpus(cloud3)
suc_tdm3 <- TermDocumentMatrix(suc_clean3)
suc_m3 <- as.matrix(suc_tdm3)
suc_v3 <- sort(rowSums(suc_m3), decreasing = TRUE)
suc_d3 <- data.frame(word = names(suc_v3), freq = suc_v3)
set.seed(1234)
wordcloud(
words = suc_d3$word,
freq = suc_d3$freq,scale = c(2, 0.4),
min.freq = 5,
max.words = 100,
random.order = FALSE,
rot.per = 0.3,
colors = brewer.pal(8, "Dark2")
)
